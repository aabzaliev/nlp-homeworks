{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import EvalPrediction\n",
    "import pandas as pd\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "from transformers.modeling_roberta import RobertaPreTrainedModel, RobertaModel, RobertaClassificationHead, SequenceClassifierOutput\n",
    "from torch import nn\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForPreTraining,\n",
    "    AutoTokenizer,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import is_main_process\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "import pandas as pd\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eat = pd.read_json('drive/MyDrive/eat_train.json')\n",
    "eat = pd.read_json('eat_train.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 fold stratified cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amabza/anaconda3/envs/eecs595/lib/python3.6/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "kfold = IterativeStratification(n_splits=10, random_state=42)\n",
    "# we create the folds once, and always use those.\n",
    "for fold, (train_index, val_index) in enumerate(kfold.split(X=eat, y=eat[['label', 'breakpoint']])):\n",
    "    eat.loc[val_index, 'fold'] = int(fold) # fold to predict on\n",
    "    \n",
    "eat['fold'] = eat['fold'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dataset and n of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EATDatasetTask1(Dataset):\n",
    "    \"\"\"Custom EAT Dataset class\"\"\"\n",
    "\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.tokens, self.y = [], []\n",
    "\n",
    "#         self.y = df['breakpoint'].replace(-1, 0).values\n",
    "        self.y = df['label'].values\n",
    "        for ix, row in df.iterrows():\n",
    "            first_sentence = \" \".join(row['story'][0:2])\n",
    "            rest = \" \".join(row['story'][2:])\n",
    "\n",
    "            one_story = tokenizer.encode_plus(first_sentence, rest, padding='max_length',\n",
    "                                        max_length=100, truncation=True)\n",
    "            \n",
    "            \n",
    "            self.tokens.append(one_story)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val) for key, val in self.tokens[idx].items()}\n",
    "        item['labels'] = torch.tensor(self.y[idx])\n",
    "        return item\n",
    "    \n",
    "def compute_metrics(pred: EvalPrediction):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "class EATDatasetTask2(Dataset):\n",
    "    \"\"\"Custom EAT Dataset class\"\"\"\n",
    "\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.tokens, self.y = [], []\n",
    "\n",
    "        self.y = df['breakpoint'].replace(-1, 0).values\n",
    "        for ix, row in df.iterrows():\n",
    "            first_sentence = \" \".join(row['story'][0:2])\n",
    "            rest = \" \".join(row['story'][2:])\n",
    "\n",
    "            one_story = tokenizer.encode_plus(first_sentence, rest, padding='max_length',\n",
    "                                        max_length=100, truncation=True)\n",
    "            \n",
    "            \n",
    "            self.tokens.append(one_story)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val) for key, val in self.tokens[idx].items()}\n",
    "        item['labels'] = torch.tensor(self.y[idx])\n",
    "        return item\n",
    "\n",
    "label_list_task2 = eat['breakpoint'].replace(-1, 0).unique()#eat_with_folds['label'].unique() #datasets[\"train\"].unique(\"label\")\n",
    "model_name_or_path = 'roberta-large-mnli'\n",
    "label_list_task2.sort()  # Let's sort it for determinism\n",
    "num_labels_task2 = len(label_list_task2)\n",
    "\n",
    "label_list_task1 = eat['label'].unique()#eat_with_folds['label'].unique() #datasets[\"train\"].unique(\"label\")\n",
    "model_name_or_path = 'roberta-large-mnli'\n",
    "label_list_task1.sort()  # Let's sort it for determinism\n",
    "num_labels_task1 = len(label_list_task1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(1024, 1024)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.final = nn.Linear(1024, 2)\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.final(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class RobertaForSequenceClassification(RobertaPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        self.classifier = RobertaClassificationHead(config)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        \n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n",
    "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        \n",
    "        sequence_output = outputs[2][-3]\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[3:] #[-1]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,#[-1],\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaClassificationHeadTask2(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(1024, 1024)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.final = nn.Linear(1024, 6)\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.final(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class RobertaForSequenceClassificationTask2(RobertaPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        self.classifier = RobertaClassificationHeadTask2(config)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        \n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n",
    "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        \n",
    "        sequence_output = outputs[2][-3]\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[3:] #[-1]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,#[-1],\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='tmp',\n",
    "                                overwrite_output_dir=True, \n",
    "                                do_train=True, \n",
    "                                do_eval=True,\n",
    "                                evaluation_strategy='epoch',\n",
    "                                per_device_train_batch_size=8,\n",
    "                                per_device_eval_batch_size=8,\n",
    "                                gradient_accumulation_steps=1,\n",
    "                                learning_rate=2e-06,\n",
    "                                weight_decay=0.0, \n",
    "                                adam_beta1=0.9, \n",
    "                                adam_beta2=0.999, \n",
    "                                adam_epsilon=1e-08, \n",
    "                                max_grad_norm=1.0, \n",
    "                                num_train_epochs=40.0,\n",
    "                                max_steps=-1, \n",
    "                                warmup_steps=0,\n",
    "                                logging_dir='runs/whataver', \n",
    "                                logging_first_step=False, \n",
    "                                logging_steps=100, \n",
    "                                load_best_model_at_end=True,\n",
    "                                metric_for_best_model='f1',\n",
    "                                seed=42, \n",
    "                                eval_steps=100,\n",
    "                                dataloader_num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training itself - don't run if the models are already trained and saved!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for fold in range(0, 10):\n",
    "    print(\"fold n#{}\".format(fold))\n",
    "    train = eat[eat['fold'] != fold]\n",
    "    val = eat[eat['fold'] == fold]\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        num_labels=num_labels_task1,\n",
    "        output_hidden_states = True\n",
    "    )\n",
    "    \n",
    "    # Load pretrained model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        use_fast=True,\n",
    "    )\n",
    "    \n",
    "    model = RobertaForSequenceClassification.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        from_tf=False,\n",
    "        config=config,\n",
    "    )\n",
    "    \n",
    "    datasets = {}\n",
    "    datasets['train'] = EATDatasetTask1(train, tokenizer)\n",
    "    datasets['val'] = EATDatasetTask1(val, tokenizer)\n",
    "    \n",
    "    train_dataset = datasets[\"train\"]\n",
    "    eval_dataset = datasets[\"val\"]\n",
    "    \n",
    "    ####################### TRAIN ######################\n",
    "    # Initialize our Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "        # Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.\n",
    "        data_collator=default_data_collator,\n",
    "    )\n",
    "    \n",
    "    trainer.train(\n",
    "        model_path=None\n",
    "    )\n",
    "    \n",
    "    res.append(trainer.evaluate(eval_dataset=eval_dataset))\n",
    "    \n",
    "    trainer.save_model(f'roberta_large_mnli_3layer_task_1_fold_{fold}')  # Saves the tokenizer too for easy upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"accuracy is {np.mean([i['eval_accuracy'] for i in res])}\")\n",
    "# print(f\"STD of acc is {np.std([i['eval_accuracy'] for i in res])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='tmp',\n",
    "                                overwrite_output_dir=True, \n",
    "                                do_train=True, \n",
    "                                do_eval=True,\n",
    "                                evaluation_strategy='epoch',\n",
    "                                per_device_train_batch_size=8,\n",
    "                                per_device_eval_batch_size=8,\n",
    "                                gradient_accumulation_steps=1,\n",
    "                                learning_rate=2e-06,\n",
    "                                weight_decay=0.0, \n",
    "                                adam_beta1=0.9, \n",
    "                                adam_beta2=0.999, \n",
    "                                adam_epsilon=1e-08, \n",
    "                                max_grad_norm=1.0, \n",
    "                                num_train_epochs=40.0,\n",
    "                                max_steps=-1, \n",
    "                                warmup_steps=0,\n",
    "                                logging_dir='runs/whataver', \n",
    "                                logging_first_step=False, \n",
    "                                logging_steps=100, \n",
    "                                seed=42, \n",
    "                                eval_steps=100,\n",
    "                                dataloader_num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for task 2 - don't run if already trained and models are saved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for fold in range(0, 10):\n",
    "    print(\"fold n#{}\".format(fold))\n",
    "    train = eat[eat['fold'] != fold]\n",
    "    val = eat[eat['fold'] == fold]\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        num_labels=num_labels_task2,\n",
    "        output_hidden_states = True\n",
    "    )\n",
    "    \n",
    "    # Load pretrained model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        use_fast=True,\n",
    "    )\n",
    "    \n",
    "    model = RobertaForSequenceClassificationTask2.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        from_tf=False,\n",
    "        config=config,\n",
    "    )\n",
    "    \n",
    "    datasets = {}\n",
    "    datasets['train'] = EATDatasetTask2(train, tokenizer)\n",
    "    datasets['val'] = EATDatasetTask2(val, tokenizer)\n",
    "    \n",
    "    train_dataset = datasets[\"train\"]\n",
    "    eval_dataset = datasets[\"val\"]\n",
    "    \n",
    "    ####################### TRAIN ######################\n",
    "    # Initialize our Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "        # Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.\n",
    "        data_collator=default_data_collator,\n",
    "    )\n",
    "    \n",
    "    trainer.train(\n",
    "        model_path=None\n",
    "    )\n",
    "    \n",
    "    res.append(trainer.evaluate(eval_dataset=eval_dataset))\n",
    "    \n",
    "    trainer.save_model(f'roberta_large_mnli_task_2_fold_{fold}')  # Saves the tokenizer too for easy upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Precision is {np.mean([i['eval_precision'] for i in res])}\")\n",
    "# print(f\"STD of precision is {np.std([i['eval_precision'] for i in res])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Recall is {np.mean([i['eval_recall'] for i in res])}\")\n",
    "# print(f\"STD of recall is {np.std([i['eval_recall'] for i in res])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"F1 is {np.mean([i['eval_f1'] for i in res])}\")\n",
    "# print(f\"STD of f1 is {np.std([i['eval_f1'] for i in res])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full predict on both tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EATTestDataset(Dataset):\n",
    "    \"\"\"Custom EAT Dataset class\"\"\"\n",
    "\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.tokens= []\n",
    "        for ix, row in df.iterrows():\n",
    "            first_sentence = \" \".join(row['story'][0:2])\n",
    "            rest = \" \".join(row['story'][2:])\n",
    "\n",
    "            one_story = tokenizer.encode_plus(first_sentence, rest, padding='max_length',\n",
    "                                        max_length=100, truncation=True)\n",
    "            \n",
    "            \n",
    "            self.tokens.append(one_story)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val) for key, val in self.tokens[idx].items()}\n",
    "        return item\n",
    "    \n",
    "test = pd.read_json('eat_test_unlabeled.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17259874939918518, 'eval_accuracy': 0.9478168264110756, 'eval_f1': 0.9478083026213251, 'eval_precision': 0.9480726107363662, 'eval_recall': 0.9478042916118496}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18603016436100006, 'eval_accuracy': 0.9659211927582535, 'eval_f1': 0.7927943402446456, 'eval_precision': 0.7972706581507997, 'eval_recall': 0.7885279105271077}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amabza/anaconda3/envs/eecs595/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2329571396112442, 'eval_accuracy': 0.9712765957446808, 'eval_f1': 0.9712757830404889, 'eval_precision': 0.9713299377475948, 'eval_recall': 0.9712765957446808}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2879768908023834, 'eval_accuracy': 0.9521276595744681, 'eval_f1': 0.7831849744768701, 'eval_precision': 0.7889962145243836, 'eval_recall': 0.7778053952872651}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amabza/anaconda3/envs/eecs595/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18549077212810516, 'eval_accuracy': 0.9478723404255319, 'eval_f1': 0.9478292978249371, 'eval_precision': 0.9493552738553216, 'eval_recall': 0.9478723404255319}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2245652824640274, 'eval_accuracy': 0.9585106382978723, 'eval_f1': 0.7910595911219359, 'eval_precision': 0.7928163152592793, 'eval_recall': 0.789407144446676}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amabza/anaconda3/envs/eecs595/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24287547171115875, 'eval_accuracy': 0.9595314164004259, 'eval_f1': 0.9595236582754053, 'eval_precision': 0.9598431952931349, 'eval_recall': 0.9595177607403711}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30689549446105957, 'eval_accuracy': 0.9371671991480298, 'eval_f1': 0.749790965277393, 'eval_precision': 0.7641750581074671, 'eval_recall': 0.7396295399861669}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amabza/anaconda3/envs/eecs595/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18740876019001007, 'eval_accuracy': 0.973404255319149, 'eval_f1': 0.9734035028152674, 'eval_precision': 0.9734950014488555, 'eval_recall': 0.9734199792665426}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28691983222961426, 'eval_accuracy': 0.9468085106382979, 'eval_f1': 0.7745163044810296, 'eval_precision': 0.7867194566213893, 'eval_recall': 0.7638334100232503}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amabza/anaconda3/envs/eecs595/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13564711809158325, 'eval_accuracy': 0.973404255319149, 'eval_f1': 0.9734039844226572, 'eval_precision': 0.973423543738767, 'eval_recall': 0.9734042553191489}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26495271921157837, 'eval_accuracy': 0.9457446808510638, 'eval_f1': 0.7714096049004868, 'eval_precision': 0.7855369874834744, 'eval_recall': 0.7596626883253363}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amabza/anaconda3/envs/eecs595/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3708890676498413, 'eval_accuracy': 0.8519701810436635, 'eval_f1': 0.8511897771854197, 'eval_precision': 0.859320714861447, 'eval_recall': 0.8518940253141587}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23418597877025604, 'eval_accuracy': 0.9542066027689031, 'eval_f1': 0.7826774987522253, 'eval_precision': 0.7871742960400367, 'eval_recall': 0.7785448372475311}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amabza/anaconda3/envs/eecs595/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16951222717761993, 'eval_accuracy': 0.9744680851063829, 'eval_f1': 0.9744662356712119, 'eval_precision': 0.9746055896683512, 'eval_recall': 0.9744680851063829}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20769107341766357, 'eval_accuracy': 0.9648936170212766, 'eval_f1': 0.7903866459959187, 'eval_precision': 0.7954240970065919, 'eval_recall': 0.7857847883028235}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amabza/anaconda3/envs/eecs595/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20725375413894653, 'eval_accuracy': 0.9468085106382979, 'eval_f1': 0.9467738136222799, 'eval_precision': 0.9481330155487458, 'eval_recall': 0.9468671202676336}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2717283070087433, 'eval_accuracy': 0.9478723404255319, 'eval_f1': 0.7817967259357811, 'eval_precision': 0.7834209050407176, 'eval_recall': 0.7817445023013757}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amabza/anaconda3/envs/eecs595/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2784635126590729, 'eval_accuracy': 0.9030883919062833, 'eval_f1': 0.9030602462945211, 'eval_precision': 0.9035106044779508, 'eval_recall': 0.9030712697908634}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='157' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2176772952079773, 'eval_accuracy': 0.9637912673056444, 'eval_f1': 0.7955637404577739, 'eval_precision': 0.7957247122404189, 'eval_recall': 0.7955255136737286}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amabza/anaconda3/envs/eecs595/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "all_predictions_task1 = list()\n",
    "all_predictions_task2 = list()\n",
    "\n",
    "for fold in range(0, 10):\n",
    "    \n",
    "    train = eat[eat['fold'] != fold]\n",
    "    val = eat[eat['fold'] == fold]\n",
    "    \n",
    "     # saved in the same directory, one folder per fold per task\n",
    "    model_name_or_path_task1 = f'roberta_large_mnli_3layer_task_1_fold_{fold}'\n",
    "    model_name_or_path_task2 = f'roberta_large_mnli_task_2_fold_{fold}'\n",
    "\n",
    "    config_task1 = AutoConfig.from_pretrained(\n",
    "        model_name_or_path_task1,\n",
    "        num_labels=num_labels_task1,\n",
    "        output_hidden_states = True\n",
    "    )\n",
    "    \n",
    "    config_task2 = AutoConfig.from_pretrained(\n",
    "        model_name_or_path_task2,\n",
    "        num_labels=num_labels_task2,\n",
    "        output_hidden_states = True\n",
    "    )\n",
    "\n",
    "    tokenizer_task1 = AutoTokenizer.from_pretrained(\n",
    "        model_name_or_path_task1,\n",
    "        use_fast=True,\n",
    "    )\n",
    "    \n",
    "    tokenizer_task2 = AutoTokenizer.from_pretrained(\n",
    "        model_name_or_path_task2,\n",
    "        use_fast=True,\n",
    "    )\n",
    "    \n",
    "    ############ PREDICT TASK 1 ##################\n",
    "    # just for sanity check that we had good accuracy on val\n",
    "    train_dataset = EATDatasetTask1(train, tokenizer_task1)\n",
    "    test_ds = EATTestDataset(test, tokenizer_task1)\n",
    "    \n",
    "    model = RobertaForSequenceClassification.from_pretrained(\n",
    "        model_name_or_path_task1,\n",
    "        from_tf=False,\n",
    "        config=config_task1,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=train_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer_task1,\n",
    "        # Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.\n",
    "        data_collator=default_data_collator,\n",
    "    )\n",
    "    \n",
    "    print(trainer.evaluate(eval_dataset=train_dataset))\n",
    "    \n",
    "    preds_task_1 = trainer.predict(test_ds)\n",
    "    all_predictions_task1.append(preds_task_1)\n",
    "    \n",
    "    ############ PREDICT TASK 2 ##################\n",
    "    train_dataset = EATDatasetTask2(train, tokenizer_task2)\n",
    "    test_ds = EATTestDataset(test, tokenizer_task2)\n",
    "    \n",
    "    model = RobertaForSequenceClassificationTask2.from_pretrained(\n",
    "        model_name_or_path_task2,\n",
    "        from_tf=False,\n",
    "        config=config_task2,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=train_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer_task2,\n",
    "        # Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.\n",
    "        data_collator=default_data_collator,\n",
    "    )\n",
    "    \n",
    "    print(trainer.evaluate(eval_dataset=train_dataset))\n",
    "    \n",
    "    preds_task_2 = trainer.predict(test_ds)\n",
    "    all_predictions_task2.append(preds_task_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble - take the average of raw logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_logits_task1 = np.concatenate([p.predictions[:,:,None] for p in all_predictions_task1], axis=2).mean(axis=2)\n",
    "average_logits_task2 = np.concatenate([p.predictions[:,:,None] for p in all_predictions_task2], axis=2).mean(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_task1 = pd.Series(average_logits_task1.argmax(-1))\n",
    "preds_task2 = pd.Series(average_logits_task2.argmax(-1)).replace(0, -1) # we replace it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_df = pd.DataFrame({'id': test['id'], 'pred_label': preds_task1, 'pred_breakpoint': preds_task2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases where task 1 model said it's plausible (label = 1), but task 2 model said it is not - we trust model 1 \n",
    "# more (higher acc) and set predictions on task 2 to -1\n",
    "final_pred_df.loc[((final_pred_df['pred_label'] == 1) & (final_pred_df['pred_breakpoint'] != -1)).values, 'pred_breakpoint'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cases where task 1 model said it's implausible (label=0), but task2 predicted -1 - plausible\n",
    "# in those cases, as I don't know which breakpoint should it be, just say it is plausible.\n",
    "# could it be better to take second max class after -1, as model 1 is better?\n",
    "final_pred_df.loc[((final_pred_df['pred_label'] == 0) & (final_pred_df['pred_breakpoint'] == -1)).values, 'pred_label'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we trust more to task1 model, so whenever we have a conflict we use task 1 predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check - should be 100% match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zeros_only1 = final_pred_df['pred_label'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_only2 = final_pred_df['pred_breakpoint'] == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(zeros_only1 == zeros_only2).sum() / len(zeros_only2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('EAT_22_preds.json', 'w') as outfile:\n",
    "    json.dump(final_pred_df.to_dict(orient='records'), outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eecs595",
   "language": "python",
   "name": "eecs595"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
