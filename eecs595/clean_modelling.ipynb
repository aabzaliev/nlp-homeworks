{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForPreTraining,\n",
    "    AutoTokenizer,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import is_main_process\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "import pandas as pd\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eat_with_folds = pd.read_pickle('./eat_with_folds.pkl')\n",
    "\n",
    "for fold in range(10):\n",
    "    print(\"fold n#{}\".format(fold))\n",
    "    train = eat_with_folds[eat_with_folds['fold'] != fold]\n",
    "    val = eat_with_folds[eat_with_folds['fold'] == fold]\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading a dataset from local csv files\n",
    "# # datasets = load_dataset(\"csv\", data_files={\"train\": 'eat_train.csv', \"validation\": 'eat_test.csv'})\n",
    "\n",
    "# class EATDataset(Dataset):\n",
    "#     \"\"\"Custom EAT Dataset class\"\"\"\n",
    "\n",
    "#     def __init__(self, df, tokenizer):\n",
    "#         # Extracts the tokens and offsets(positions of A, B, and P)\n",
    "#         self.tokens, self.y = [], []\n",
    "# #         self.tokens = tokenizer(df['story'].apply(lambda x: ' '.join(x)).tolist(), padding='max_length',\n",
    "# #                                         max_length=256, truncation=True)\n",
    "#         self.y = df['breakpoint'].replace(-1, 0).values\n",
    "\n",
    "#         for ix, row in df.iterrows():\n",
    "# #             one_story = tokenizer(\" \".join(row['story']), padding='max_length',\n",
    "# #                                         max_length=256, truncation=True)\n",
    "            \n",
    "#             one_story = []\n",
    "#             one_story_attentions = []\n",
    "#             one_story_token_type_ids = []\n",
    "            \n",
    "#             for ix1 in range(1, 4):\n",
    "#                 for ix2 in range(ix1, 5):\n",
    "#                     if ix1 != ix2:\n",
    "#                         sent = row['story'][:0]\n",
    "#                         sent2 = row['story'][ix2]\n",
    "#                         tokenized = tokenizer.encode_plus(sent, \n",
    "#                                                           sent2,\n",
    "#                                         padding='max_length',\n",
    "#                                         max_length=50, truncation=True)\n",
    "\n",
    "#                         one_story.append(tokenized['input_ids'])\n",
    "#                         one_story_attentions.append(tokenized['attention_mask'])\n",
    "\n",
    "#             self.tokens.append(one_story)\n",
    "    \n",
    "# #         y = np.zeros(shape=(2,), dtype=bool)\n",
    "# #         y[row['label']] = True\n",
    "# #         self.y.append(y)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.y)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         item = {key: torch.tensor(val) for key, val in self.tokens[idx].items()}\n",
    "#         item['labels'] = torch.tensor(self.y[idx])\n",
    "#         return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a dataset from local csv files\n",
    "# datasets = load_dataset(\"csv\", data_files={\"train\": 'eat_train.csv', \"validation\": 'eat_test.csv'})\n",
    "\n",
    "class EATDataset(Dataset):\n",
    "    \"\"\"Custom EAT Dataset class\"\"\"\n",
    "\n",
    "    def __init__(self, df, tokenizer):\n",
    "        # Extracts the tokens and offsets(positions of A, B, and P)\n",
    "        self.tokens, self.y = [], []\n",
    "#         self.tokens = tokenizer(df['story'].apply(lambda x: ' '.join(x)).tolist(), padding='max_length',\n",
    "#                                         max_length=256, truncation=True)\n",
    "        self.y = df['breakpoint'].replace(-1, 0).values\n",
    "#         self.y = df['label'].values\n",
    "        for ix, row in df.iterrows():\n",
    "            first_sentence = \" \".join(row['story'][0:2])\n",
    "            rest = \" \".join(row['story'][2:])\n",
    "\n",
    "            one_story = tokenizer.encode_plus(first_sentence, rest, padding='max_length',\n",
    "                                        max_length=100, truncation=True)\n",
    "            \n",
    "            \n",
    "            self.tokens.append(one_story)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val) for key, val in self.tokens[idx].items()}\n",
    "        item['labels'] = torch.tensor(self.y[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.quantile([len(one_story['input_ids']) for one_story in self.tokens], 0.97))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading a dataset from local csv files\n",
    "# # datasets = load_dataset(\"csv\", data_files={\"train\": 'eat_train.csv', \"validation\": 'eat_test.csv'})\n",
    "\n",
    "# class EATDataset(Dataset):\n",
    "#     \"\"\"Custom EAT Dataset class\"\"\"\n",
    "\n",
    "#     def __init__(self, df, tokenizer):\n",
    "#         # Extracts the tokens and offsets(positions of A, B, and P)\n",
    "#         self.tokens, self.y = [], []\n",
    "# #         self.tokens = tokenizer(df['story'].apply(lambda x: ' '.join(x)).tolist(), padding='max_length',\n",
    "# #                                         max_length=256, truncation=True)\n",
    "#         self.y = df['breakpoint'].replace(-1, 0).values\n",
    "        \n",
    "#         one_story_sentences = list()\n",
    "#         for ix, row in df.iterrows():\n",
    "#             for ix in range(5):\n",
    "                \n",
    "#                 first_sentence = row['story'][ix]\n",
    "#                 rest = \" \".join(row['story'][ix+1:])\n",
    "\n",
    "#                 one_story = tokenizer.encode_plus(first_sentence, rest, padding='max_length',\n",
    "#                                             max_length=256, truncation=True)\n",
    "            \n",
    "#                 one_story_sentences.append(one_story)\n",
    "                \n",
    "#             self.tokens.append(one_story_sentences)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.y)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         item = {key: torch.tensor(val) for key, val in self.tokens[idx].items()}\n",
    "#         item['labels'] = torch.tensor(self.y[idx])\n",
    "#         return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred: EvalPrediction):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A useful fast method:\n",
    "# https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.unique\n",
    "label_list = eat_with_folds['breakpoint'].replace(-1, 0).unique()#eat_with_folds['label'].unique() #datasets[\"train\"].unique(\"label\")\n",
    "model_name_or_path = 'roberta-large-mnli'\n",
    "label_list.sort()  # Let's sort it for determinism\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    output_hidden_states = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    use_fast=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_albert import AlbertPreTrainedModel, AlbertModel\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_roberta import RobertaPreTrainedModel, RobertaModel, RobertaClassificationHead, SequenceClassifierOutput\n",
    "from torch import nn\n",
    "\n",
    "class RobertaClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(1024, 1024)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.final = nn.Linear(1024, 6)\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.final(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class RobertaForSequenceClassification(RobertaPreTrainedModel):\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\"]\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        self.classifier = RobertaClassificationHead(config)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        \n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n",
    "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        \n",
    "        sequence_output = outputs[2][-7]\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[3:] #[-1]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,#[-1],\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    from_tf=False,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.classifier.out_proj = nn.Linear(in_features=1024, out_features=6, bias=True)\n",
    "# model.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     model_name_or_path,\n",
    "#     from_tf=False,\n",
    "#     config=config,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "datasets['train'] = EATDataset(train, tokenizer)\n",
    "datasets['val'] = EATDataset(val, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    datasets['train'],\n",
    "    batch_size=16,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tokenizer.encode_plus(\"I ate the apple\", \"I have thrown the apple away\", padding='max_length',\n",
    "                                        max_length=64, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = iter(train_loader)\n",
    "b = next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weimerw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = model(torch.Tensor(b['input_ids']).unsqueeze(0).long(), torch.Tensor(b['attention_mask']).unsqueeze(0).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_label_column_names = [name for name in datasets[\"train\"].column_names if name != \"label\"]\n",
    "# sentence1_key, sentence2_key = non_label_column_names[0], None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_to_max_length = True\n",
    "max_seq_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding strategy\n",
    "if pad_to_max_length:\n",
    "    padding = \"max_length\"\n",
    "    max_length = max_seq_length\n",
    "else:\n",
    "    # We will pad later, dynamically at batch creation, to the max sequence length in each batch\n",
    "    padding = False\n",
    "    max_length = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_function(examples):\n",
    "#     # Tokenize the texts\n",
    "#     args = (\n",
    "#         (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "#     )\n",
    "#     result = tokenizer(*args, padding=padding, max_length=max_length, truncation=True)\n",
    "\n",
    "#     # Map labels to IDs (not necessary for GLUE tasks)\n",
    "#     if label_to_id is not None and \"label\" in examples:\n",
    "#         result[\"label\"] = [label_to_id[l] for l in examples[\"label\"]]\n",
    "#     return result\n",
    "\n",
    "# datasets = preprocess_function() for i in datasets (, batched=True, load_from_cache_file=False)\n",
    "\n",
    "# label_to_id = {v: i for i, v in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets[\"train\"]\n",
    "eval_dataset = datasets[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Log a few random samples from the training set:\n",
    "# for index in random.sample(range(len(train_dataset)), 3):\n",
    "#     logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Own training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.base_model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='./deleteme',#output_dir=f'./roberta_fold{fold}_task2',\n",
    "                                overwrite_output_dir=True, \n",
    "                                do_train=True, \n",
    "                                do_eval=True,\n",
    "                                evaluation_strategy='epoch',\n",
    "                                per_device_train_batch_size=8,\n",
    "                                per_device_eval_batch_size=8,\n",
    "                                gradient_accumulation_steps=1,\n",
    "                                learning_rate=2e-07,\n",
    "                                weight_decay=0.0, \n",
    "                                adam_beta1=0.9, \n",
    "                                adam_beta2=0.999, \n",
    "                                adam_epsilon=1e-08, \n",
    "                                max_grad_norm=1.0, \n",
    "                                num_train_epochs=40.0,\n",
    "                                max_steps=-1, \n",
    "                                warmup_steps=0,\n",
    "                                logging_dir='runs/whataver', \n",
    "                                logging_first_step=False, \n",
    "                                logging_steps=100, \n",
    "                                load_best_model_at_end=True,\n",
    "                                metric_for_best_model='f1',\n",
    "                                seed=42, \n",
    "                                eval_steps=100,\n",
    "                                dataloader_num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### TRAIN ######################\n",
    "# Initialize our Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    # Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.\n",
    "    data_collator=default_data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train(\n",
    "    model_path=None\n",
    ")\n",
    "\n",
    "# trainer.save_model()  # Saves the tokenizer too for easy upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_picture = [{'layer': '24', 'bert': 0.37, 'roberta': 0.56},\n",
    "{'layer': '23', 'bert': 0.3734, 'roberta': 0.69},\n",
    "{'layer': '22', 'bert': 0.4, 'roberta': 0.71},\n",
    "{'layer': '21', 'bert': 0.45, 'roberta': 0.7056},\n",
    "{'layer': '20', 'bert': 0.38, 'roberta': 0.6815},\n",
    "{'layer': '19', 'bert': 0.36, 'roberta': 0.5578},\n",
    "{'layer': '18', 'bert': 0.34, 'roberta': 0.4897}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_picture = pd.DataFrame(to_picture).set_index('layer').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with plt.style.context('ggplot'):\n",
    "    f, ax = plt.subplots(1, 1, figsize=(16, 9), dpi=300);\n",
    "    ax.plot(to_picture['roberta'], lw=1.5, color='tab:red')\n",
    "    # Decorations    \n",
    "    plt.tick_params(axis=\"both\", which=\"both\", bottom=False, top=False,    \n",
    "                    labelbottom=True, left=False, right=False, labelleft=True)        \n",
    "\n",
    "    # Lighten borders\n",
    "    plt.gca().spines[\"top\"].set_alpha(.3)\n",
    "    plt.gca().spines[\"bottom\"].set_alpha(.3)\n",
    "    plt.gca().spines[\"right\"].set_alpha(.3)\n",
    "    plt.gca().spines[\"left\"].set_alpha(.3)\n",
    "\n",
    "    plt.title('Effect of layer choice on F1 score', fontsize=34)\n",
    "    plt.xlabel('Layer', fontsize=22)\n",
    "    plt.ylabel('F1 score', fontsize=22)\n",
    "    plt.yticks(fontsize=22) \n",
    "    plt.xticks(fontsize=22) \n",
    "    # plt.yticks(range(y_LL, y_UL, y_interval), [str(y) for y in range(y_LL, y_UL, y_interval)], fontsize=12)    \n",
    "    # plt.xticks(range(0, df.shape[0], 12), df.date.values[::12], horizontalalignment='left', fontsize=12)    \n",
    "    # plt.ylim(y_LL, y_UL)    \n",
    "    # plt.xlim(-2, 80)    \n",
    "#     plt.show()\n",
    "    plt.savefig('layer_vs_f1_roberta.jpg', dpi=300)\n",
    "    # ax.text(5, 0.5, 'f1 score', fontsize=14, color='tab:red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-1 0.548 acc, 0.37 f1\n",
    "-2 0.567 acc, 0.3734 f1\n",
    "-3 0.5769 acc, 0.4 f1\n",
    "-4 0.58 acc, 0.45 f1\n",
    "-5 0.54 acc, 0.38 f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(eval_dataset=eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for fold in range(0, 10):\n",
    "    print(\"fold n#{}\".format(fold))\n",
    "    train = eat_with_folds[eat_with_folds['fold'] != fold]\n",
    "    val = eat_with_folds[eat_with_folds['fold'] == fold]\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        num_labels=num_labels,\n",
    "        output_hidden_states = True\n",
    "    )\n",
    "    \n",
    "    # Load pretrained model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        use_fast=True,\n",
    "    )\n",
    "    \n",
    "    model = RobertaForSequenceClassification.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        from_tf=False,\n",
    "        config=config,\n",
    "    )\n",
    "    \n",
    "    datasets = {}\n",
    "    datasets['train'] = EATDataset(train, tokenizer)\n",
    "    datasets['val'] = EATDataset(val, tokenizer)\n",
    "    \n",
    "    train_dataset = datasets[\"train\"]\n",
    "    eval_dataset = datasets[\"val\"]\n",
    "    \n",
    "    training_args = TrainingArguments(output_dir='tmp',\n",
    "                                overwrite_output_dir=True, \n",
    "                                do_train=True, \n",
    "                                do_eval=True,\n",
    "                                evaluation_strategy='epoch',\n",
    "                                per_device_train_batch_size=8,\n",
    "                                per_device_eval_batch_size=8,\n",
    "                                gradient_accumulation_steps=1,\n",
    "                                learning_rate=2e-06,\n",
    "                                weight_decay=0.0, \n",
    "                                adam_beta1=0.9, \n",
    "                                adam_beta2=0.999, \n",
    "                                adam_epsilon=1e-08, \n",
    "                                max_grad_norm=1.0, \n",
    "                                num_train_epochs=40.0,\n",
    "                                max_steps=-1, \n",
    "                                warmup_steps=0,\n",
    "                                logging_dir='runs/whataver', \n",
    "                                logging_first_step=False, \n",
    "                                logging_steps=100, \n",
    "                                load_best_model_at_end=True,\n",
    "                                metric_for_best_model='f1',\n",
    "                                seed=42, \n",
    "                                eval_steps=100,\n",
    "                                dataloader_num_workers=0)\n",
    "    \n",
    "    ####################### TRAIN ######################\n",
    "    # Initialize our Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "        # Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.\n",
    "        data_collator=default_data_collator,\n",
    "    )\n",
    "    \n",
    "    trainer.train(\n",
    "        model_path=None\n",
    "    )\n",
    "    \n",
    "    res.append(trainer.evaluate(eval_dataset=eval_dataset))\n",
    "    break\n",
    "#     trainer.save_model(f'roberta_large_mnli_task_1_fold_{fold}')  # Saves the tokenizer too for easy upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c08785e04264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Acc is {np.mean([i['eval_accuracy'] for i in res])}\")\n",
    "print(f\"STD of acc is {np.std([i['eval_accuracy'] for i in res])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load best performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for fold in range(0, 1):\n",
    "    \n",
    "    # because we already pre-trained\n",
    "    model_name_or_path = f'./roberta_fold{fold}_task2'\n",
    "    \n",
    "    print(\"fold n#{}\".format(fold))\n",
    "    train = eat_with_folds[eat_with_folds['fold'] != fold]\n",
    "    val = eat_with_folds[eat_with_folds['fold'] == fold]\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        num_labels=num_labels,\n",
    "        output_hidden_states = False\n",
    "    )\n",
    "    \n",
    "    # Load pretrained model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        use_fast=True,\n",
    "    )\n",
    "    \n",
    "    model = AutoModel.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        from_tf=False,\n",
    "        config=config,\n",
    "    )\n",
    "    \n",
    "    datasets = {}\n",
    "    datasets['train'] = EATDataset(train, tokenizer)\n",
    "    datasets['val'] = EATDataset(val, tokenizer)\n",
    "    \n",
    "    train_dataset = datasets[\"train\"]\n",
    "    eval_dataset = datasets[\"val\"]\n",
    "    \n",
    "    \n",
    "#     training_args = TrainingArguments(output_dir=f'./roberta_fold{fold}',\n",
    "#                         overwrite_output_dir=True, \n",
    "#                                 do_train=True, \n",
    "#                                 do_eval=True,\n",
    "#                                 evaluation_strategy='epoch',\n",
    "#                                 per_device_train_batch_size=8,\n",
    "#                                 per_device_eval_batch_size=8,\n",
    "#                                 gradient_accumulation_steps=1,\n",
    "#                                 learning_rate=2e-06,\n",
    "#                                 weight_decay=0.0, \n",
    "#                                 adam_beta1=0.9, \n",
    "#                                 adam_beta2=0.999, \n",
    "#                                 adam_epsilon=1e-08, \n",
    "#                                 max_grad_norm=1.0, \n",
    "#                                 num_train_epochs=20.0,\n",
    "#                                 max_steps=-1, \n",
    "#                                 warmup_steps=0,\n",
    "#                                 logging_dir='runs/whataver', \n",
    "#                                 logging_first_step=False, \n",
    "#                                 logging_steps=100, \n",
    "#                                 save_steps=500,\n",
    "#                                 seed=42, \n",
    "#                                 eval_steps=100,\n",
    "#                                 dataloader_num_workers=0)\n",
    "    \n",
    "    ####################### TRAIN ######################\n",
    "    # Initialize our Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "        # Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.\n",
    "        data_collator=default_data_collator,\n",
    "    )\n",
    "    \n",
    "    res.append(trainer.evaluate(eval_dataset=eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c08785e04264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Precision is {np.mean([i['eval_precision'] for i in res])}\")\n",
    "print(f\"STD of precision is {np.std([i['eval_precision'] for i in res])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Recall is {np.mean([i['eval_recall'] for i in res])}\")\n",
    "print(f\"STD of recall is {np.std([i['eval_recall'] for i in res])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 is {np.mean([i['eval_f1'] for i in res])}\")\n",
    "print(f\"STD of f1 is {np.std([i['eval_f1'] for i in res])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([i['eval_f1'] for i in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([i['eval_f1'] for i in res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To picture label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% of examples</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breakpoint</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            % of examples\n",
       "Breakpoint               \n",
       "-1                  0.500\n",
       " 1                  0.050\n",
       " 2                  0.080\n",
       " 3                  0.100\n",
       " 4                  0.250\n",
       " 5                  0.004"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([(-1, 0.5), (4, 0.25), (3, 0.1), (2, 0.08), (1, 0.05), (5, 0.004)], columns=['Breakpoint', '% of examples']).set_index('Breakpoint').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_picture = pd.DataFrame(to_picture)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eecs595",
   "language": "python",
   "name": "eecs595"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
